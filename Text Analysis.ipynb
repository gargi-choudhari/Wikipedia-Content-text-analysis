{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19c585f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df = pd.read_csv('ogsample.csv')\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "texts = df['Content']\n",
    "\n",
    "tokenized_texts = [word_tokenize(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa0cae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "# Preprocess the text\n",
    "df['tokens'] = df['Content'].apply(simple_preprocess)\n",
    "\n",
    "# Train Word2Vec model\n",
    "model = Word2Vec(sentences=df['tokens'], vector_size=300, window=5 , min_count=15, workers=4, sg=0, epochs=10)\n",
    "\n",
    "# Save the model for later use\n",
    "model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1c0593",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.wv.key_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b764bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate embeddings\n",
    "print(model.wv.most_similar('woman'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34233d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate embeddings\n",
    "print(model.wv.most_similar('man'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35afdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate embeddings\n",
    "print(model.wv.most_similar('government'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7be6c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the cosine similarity between \"man\" and \"woman\"\n",
    "similarity = model.wv.similarity('man', 'woman')\n",
    "\n",
    "print(f\"Cosine similarity between 'man' and 'woman': {similarity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25cbd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the cosine similarity between \"man\" and \"woman\"\n",
    "similarity = model.wv.similarity('male', 'female')\n",
    "\n",
    "print(f\"Cosine similarity between 'male' and 'female': {similarity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56eacb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Train Word2Vec model\n",
    "model = Word2Vec(sentences=df['tokens'], vector_size=300, window=5 , min_count=15, workers=4, sg=0, epochs=10)\n",
    "\n",
    "# Save the model for later use\n",
    "model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4cf56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target and attribute word sets\n",
    "career_words = ['parliament', 'conservative', 'member', 'election', 'labour', 'vote', 'party', 'parliamentary', 'mp', 'government', \n",
    "                 'work', 'become', 'serve', 'state', 'elect', 'seat', 'support', 'campaign', 'career', 'public', 'minister', 'first', \n",
    "                 'candidate', 'record', 'leader', 'secretary', 'whip', 'political', 'brexit', 'secretary', 'lord', 'common'\n",
    "                 'leadership', 'local', 'take', 'announce', 'shadow', 'majority', 'constituency', 'contribution', \n",
    "                 'office', 'liberal', 'politician', 'policy', 'resign', 'hold', 'committee', 'service', \n",
    "                 'position', 'lose', 'select', 'lead', 'voting', 'contest', 'defeat', 'chair', 'deputy',\n",
    "                 'council', 'represent', 'gain', 'number', 'sit','promote', 'trade', 'replace', 'speak', 'result', 'reelect', 'post', 'oppose', \n",
    "                 'rule', 'publish', 'debate', 'raise', 'referendum', 'mlp', 'mps', 'memo']\n",
    "personal_life_words = ['bear', 'personal', 'private', 'family', 'marry', 'university', 'young', \n",
    "                       'degree', 'marriage', 'name', 'death' , 'son' , 'daughter', 'college', 'friend',  \n",
    "                       'die', 'couple', 'mother', 'parent', 'husband', 'girl', 'cancer', 'partner', \n",
    "                       'wife', 'father', 'doctor', 'divorce', 'race', 'actress',  'author', 'brother', \n",
    "                       'blog', 'married', 'lawyer', 'bachelor', 'character', 'birthday', 'ba', 'phd', \n",
    "                       'grandfather', 'actor', 'grandchild', 'pretty', 'ugly', 'grandparent', 'sibling', \n",
    "                       'singer', 'widow', 'childhood', 'hobby', 'surname', 'grandson', 'footballer', 'doctorate', \n",
    "                       'nickname', 'autobiography', 'twin', 'tall', 'darling', 'paternal', 'aunt', 'miscarriage', \n",
    "                       'blogger', 'granddaughter',  'lover', 'cousin', 'sisterinlaw', 'stepson']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a4e43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "   \n",
    "# Load the trained Word2Vec model\n",
    "model = Word2Vec.load(\"word2vec.model\")\n",
    "   \n",
    "# Get the word vectors\n",
    "word_vectors = model.wv\n",
    "\n",
    "# Calculate WEAT scores\n",
    "weat_scores = []\n",
    "for tokens in df['tokens']:\n",
    "    # Calculate cosine similarity\n",
    "    cos_sim_career = np.mean([np.dot(word_vectors[word], word_vectors[token]) / (np.linalg.norm(word_vectors[word]) * np.linalg.norm(word_vectors[token])) for word in career_words for token in tokens if word in word_vectors and token in word_vectors])\n",
    "    cos_sim_personal_life = np.mean([np.dot(word_vectors[word], word_vectors[token]) / (np.linalg.norm(word_vectors[word]) * np.linalg.norm(word_vectors[token])) for word in personal_life_words for token in tokens if word in word_vectors and token in word_vectors])\n",
    "\n",
    "    # Calculate WEAT score\n",
    "    weat_score = cos_sim_career - cos_sim_personal_life\n",
    "    weat_scores.append(weat_score)\n",
    "\n",
    "# Add WEAT scores to the DataFrame\n",
    "df['WEAT_score'] = weat_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546926f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b337b8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('ogsample2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e02cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def count_references(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    reference_list = soup.find('ol', {'class': 'references'})\n",
    "    if reference_list is None:\n",
    "        return 0\n",
    "    else:\n",
    "        return len(reference_list.find_all('li'))\n",
    "\n",
    "# Load data from CSV\n",
    "df = pd.read_csv('ogsample2.csv')  # replace 'filename.csv' with your CSV file name\n",
    "\n",
    "# Create a new column 'reference_count' by applying the function to the 'name' column\n",
    "df['reference_count'] = df['Name'].apply(lambda x: count_references('https://en.wikipedia.org/wiki/' + x))\n",
    "\n",
    "# # Save the DataFrame to a new CSV file\n",
    "# df.to_csv('output.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a06d3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipediaapi\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2588ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05390d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download('punkt')\n",
    "\n",
    "# # Read the CSV file containing names\n",
    "# names_df = pd.read_csv(r\"C:\\Users\\gargi\\Desktop\\Jupyter Notebook\\Dissertation1.csv\")\n",
    "\n",
    "# Create empty lists to store the counts\n",
    "positive_counts = []\n",
    "negative_counts = []\n",
    "neutral_counts = []\n",
    "total_counts = []\n",
    "\n",
    "# Initialize the sentiment analyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "\n",
    "#Perform sentiment analysis and count sentences for each name\n",
    "for name in df['Name']:\n",
    "    # Fetch Wikipedia page content\n",
    "    url = f\"https://en.wikipedia.org/wiki/{name}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        # Extract the page content\n",
    "        page_content = response.text\n",
    "\n",
    "        # Tokenize the page content into sentences\n",
    "        sentences = nltk.sent_tokenize(page_content)\n",
    "\n",
    "        # Initialize counters for positive, negative, and neutral sentences\n",
    "        pos_count = 0\n",
    "        neg_count = 0\n",
    "        neu_count = 0\n",
    "        total_count = len(sentences)\n",
    "\n",
    "        # Perform sentiment analysis and count sentences\n",
    "        for sentence in sentences:\n",
    "            sentiment_scores = sia.polarity_scores(sentence)\n",
    "            if sentiment_scores['compound'] > 0:\n",
    "                pos_count += 1\n",
    "            elif sentiment_scores['compound'] < 0:\n",
    "                neg_count += 1\n",
    "            else:\n",
    "                neu_count += 1\n",
    "                \n",
    "         # Append the counts to the respective lists\n",
    "        positive_counts.append(pos_count)\n",
    "        negative_counts.append(neg_count)\n",
    "        neutral_counts.append(neu_count)\n",
    "        total_counts.append(total_count)\n",
    "    else:\n",
    "        print(f\"Error fetching Wikipedia page for {name}\")\n",
    "        \n",
    "# Add the counts as new rows in the DataFrame\n",
    "df['Positive Sentences'] = positive_counts\n",
    "df['Negative Sentences'] = negative_counts\n",
    "df['Neutral Sentences'] = neutral_counts\n",
    "df['Total Sentences'] = total_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebf2585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame to include only female politicians\n",
    "female_politicians = df.loc[df['Gender'] == 'Female']\n",
    "male_politicians = df.loc[df['Gender'] == 'Male']\n",
    "# Calculate the mean value of positive sentences for female politicians\n",
    "mean_positive_female = female_politicians['Positive Sentences'].mean()\n",
    "mean_positive_male = male_politicians['Positive Sentences'].mean()\n",
    "mean_negative_female = female_politicians['Negative Sentences'].mean()\n",
    "mean_negative_male = male_politicians['Negative Sentences'].mean()\n",
    "mean_total_female = female_politicians['Total Sentences'].mean()\n",
    "mean_total_male = male_politicians['Total Sentences'].mean()\n",
    "\n",
    "# Print the mean value\n",
    "print(f\"Mean positive sentences for female politicians: {mean_positive_female}\")\n",
    "print(f\"Mean positive sentences for male politicians: {mean_positive_male}\")\n",
    "print(f\"Mean negative sentences for female politicians: {mean_negative_female}\")\n",
    "print(f\"Mean negative sentences for male politicians: {mean_negative_male}\")\n",
    "print(f\"Mean total sentences for female politicians: {mean_total_female}\")\n",
    "print(f\"Mean total sentences for male politicians: {mean_total_male}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3482bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Create a new column and assign 1 if gender is male, else assign 0\n",
    "df['GenderCode'] = np.where(df['Gender'] == 'Male', 1, 0)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d944ab4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('ogsample3.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
